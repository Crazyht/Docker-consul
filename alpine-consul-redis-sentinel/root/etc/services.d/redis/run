#!/usr/bin/with-contenv sh

set -eux

readonly service_domain="_$CONSUL_REDIS_SVCNAME._tcp.service.$CONSUL_DC.$CONSUL_DOMAIN"
readonly service_master="_$CONSUL_REDIS_SVCNAME._master.service.$CONSUL_DC.$CONSUL_DOMAIN"
readonly sentinel_domain="_$CONSUL_SENTINEL_SVCNAME._tcp.service.$CONSUL_DC.$CONSUL_DOMAIN"

wait_consul_leader () {
  set +e
  local leader="$(curl -s http://127.0.0.1:8500/v1/status/leader)"
  echo "==${leader}=="
  while [ ! -n "$leader" ] || [ "$leader" == "No known Consul servers" ] || [ "$leader" == "\"\"" ]
  do
    sleep 1s
    leader="$(curl -s http://127.0.0.1:8500/v1/status/leader)"
    echo "==${leader}=="
  done
  echo "Consul leader : $leader"
  set -e
}
redis_info () {
  set +e
  timeout -t 10 redis-cli -h "$1" -p $REDIS_PORT info replication
  set -e
}
reset_sentinel () {
  set +e
  timeout -t 10 redis-cli -h "$1" -p $SENTINEL_PORT sentinel reset mymaster
  set -e
}

redis_info_role () {
  echo "$1" | grep -e '^role:' | cut -d':' -f2 | tr -d '[:space:]'
}

domain_ip () {
  dig "$1" A +short | head -1 | awk '{print $NF}'
}

server_domains () {
  dig "$1" SRV +short | awk '{print $NF}' | sed 's/\.$//g'
}

# At the end of the (succeeded) script, resetting all sentinels is necessary.
# This updates the list of supervised slaves.
# If this task is omitted, the number of "supervised" slaves continues to
# increase because sentinels are unable to recognize the recovered slave
# is the same slave as the dead one.
# Kubernetes may change Pod's IP address on restart.
reset_all_sentinels () {
  local sentinel_servers
  sentinel_servers="$(server_domains "$sentinel_domain")"
  readonly sentinel_servers
  local s
  >&2 echo "Resetting all sentinels: $sentinel_servers"
  for s in $sentinel_servers; do
    local s_ip
    s_ip="$(domain_ip "$s")"

    if [ -z "$s_ip" ]; then
      >&2 echo "Failed to resolve: $s"
      continue
    fi

    # Ignoring failed sentinels are allowed, since most of the sentinels are
    # expected to be alive.
    reset_sentinel "$s_ip"
  done
}

# It's okay to fail during failover or other unpredictable states.
# This prevents from making things much worse.
run () {
  wait_consul_leader
  local retry_max=60
  local retry_count=1

  local master_ip=''

  while [ -z "$master_ip" ] && [ $retry_count -lt $retry_max ]
  do
    retry_count=$((retry_count+1))
    sleep 1s
    # Headless Service allows newly added Redis server to scan all working servers.
    # This enables it to find if it is the first one.
    local redis_servers
    redis_servers="$(server_domains "$service_master")"

    local s
    for s in $redis_servers; do
        local s_ip
        s_ip="$(domain_ip "$s")"

        if [ -z "$s_ip" ]; then
          >&2 echo "Failed to resolve: $s"
          continue
        fi

        local i
        i="$(redis_info "$s_ip")"
        if [ -n "$i" ]; then
          if [ "$(redis_info_role "$i")" = 'master' ]; then
            master_ip="$s_ip"
          fi
        else
          >&2 echo "Unable to get Replication INFO: $s ($s_ip)"
          continue
        fi
    done
  done

  if [ -z "$master_ip" ]; then
    >&2 echo "Master not found."
    exit 1
  fi

  < /etc/sentinel.template.conf sed "s/%MASTERIP%/$master_ip/g" | \
    sed "s/%SENTINEL_PORT%/$SENTINEL_PORT/g" | \
    sed "s/%REDIS_PORT%/$REDIS_PORT/g" | \

    sed "s/%SENTINEL_FAILOVER_TIMEOUT%/$SENTINEL_FAILOVER_TIMEOUT/g" | \
    sed "s/%SENTINEL_DOWN_AFTER%/$SENTINEL_DOWN_AFTER/g" | \
    sed "s/%SENTINEL_QUORUM%/$SENTINEL_QUORUM/g" | \
    sed "s/%SENTINEL_PARALLEL_SYNC%/$SENTINEL_PARALLEL_SYNC/g" | \
    sed "s/%PASSWORD%/$service_domain/g" > /etc/sentinel.conf
    s6-setuidgid redis redis-server /etc/sentinel.conf --sentinel
  #exec docker-entrypoint.sh redis-sentinel "$@"
}

run "$@"
